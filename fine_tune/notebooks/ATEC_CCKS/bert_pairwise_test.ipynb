{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "BERT_FINE_TUNE_PATH = '../../bert_fine_tune/'\n",
    "sys.path.append(BERT_FINE_TUNE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "INFO:pytorch_pretrained_bert.modeling_fine_tune:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "# from textpair.preprocess.dummy_preprocessor import DummyPreprocessor\n",
    "# from textpair.analyze.bert_analyzer import BertAnalyzer\n",
    "# from textpair.vectorize.bert_vectorizer import BertVectorizer\n",
    "# from textpair.model.bert_model import BertModel\n",
    "# from textpair.pair_ann import PairAnn\n",
    "# from textpair.semantic.base_semantic import BaseSemantic\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import torch\n",
    "from pytorch_pretrained_bert.modeling_fine_tune import BertForPairWiseClassification\n",
    "from pytorch_pretrained_bert import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINE_TUNED_PATH = '/efs/fine_tune/atec_ccks_fine_tune_5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_pretrained_bert.modeling_fine_tune:loading weights file /efs/fine_tune/atec_ccks_fine_tune_5/pytorch_model.bin\n",
      "INFO:pytorch_pretrained_bert.modeling_fine_tune:loading configuration file /efs/fine_tune/atec_ccks_fine_tune_5/config.json\n",
      "INFO:pytorch_pretrained_bert.modeling_fine_tune:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 21128\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file /efs/fine_tune/atec_ccks_fine_tune_5/vocab.txt\n"
     ]
    }
   ],
   "source": [
    "model = BertForPairWiseClassification.from_pretrained(FINE_TUNED_PATH)\n",
    "tokenizer = BertTokenizer.from_pretrained(FINE_TUNED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_sim(text1, text2):\n",
    "    tokens1 = ['[CLS]'] + tokenizer.tokenize(text1) + ['[SEP]']\n",
    "    tokens2 = ['[CLS]'] + tokenizer.tokenize(text2) + ['[SEP]']\n",
    "    ids1 = tokenizer.convert_tokens_to_ids(tokens1)\n",
    "    ids2 = tokenizer.convert_tokens_to_ids(tokens2)\n",
    "    segs1 = [0] * len(ids1)\n",
    "    segs2 = [0] * len(ids2)\n",
    "    tokens_tensor1 = torch.tensor([ids1])\n",
    "    segments_tensor1 = torch.tensor([segs1])\n",
    "    tokens_tensor2 = torch.tensor([ids2])\n",
    "    segments_tensor2 = torch.tensor([segs2])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        cos_sim, pos_prob, vec1, vec2 = model(tokens_tensor1, tokens_tensor2, segments_tensor1, segments_tensor2)\n",
    "    return cos_sim.item(), pos_prob.item(), vec1, vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48099759221076965, 0.7404987812042236)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我很开心\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5408033132553101, 0.770401656627655)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我特别特别开心\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3133081793785095, 0.6566541194915771)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我其实觉得自己很开心\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7104029059410095, 0.8552014827728271)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我特别特别开心\"\n",
    "text2 = \"我其实觉得自己很开心\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.19968432188034058, 0.4001578390598297)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我不开心\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6175767779350281, 0.8087884187698364)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"车头如何放置车牌\"\n",
    "text2 = \"前牌照怎么装\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4713800251483917, 0.7356899976730347)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"车头如何放置车牌\"\n",
    "text2 = \"如何办理北京车牌\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5527295470237732, 0.776364803314209)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"车头如何放置车牌\"\n",
    "text2 = \"后牌照怎么装\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10790378600358963, 0.5539519190788269)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我不高兴\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998999834060669, 0.9999499917030334)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我很高兴\"\n",
    "text2 = \"我很高兴\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.47118473052978516, 0.7355923652648926)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"为什么能开出腾讯信用却没有微粒贷朋友的没用腾讯信用却有30000的额度呢\"\n",
    "text2 = \"我钱包里没有你们这个应用\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.26280340552330017, 0.3685982823371887)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"我也不知道\"\n",
    "text2 = \"好吧\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39961937069892883, 0.6998096704483032)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"深度学习\"\n",
    "text2 = \"机器学习\"\n",
    "cos_sim, pos_prob, vec1, vec2 = bert_sim(text1, text2)\n",
    "cos_sim, pos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
